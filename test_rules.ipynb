{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from collections import defaultdict\n",
    "from itertools import zip_longest\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('openAI.key', 'r') as file:\n",
    "    openAI_key = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai.api_key = \"\"#todo remove or make it read from a doc that I dont submit.\n",
    "client = OpenAI(\n",
    "    api_key=openAI_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-3.5-turbo\"#using this one cause gpt4 is expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_than_rule(number):\n",
    "    return number < 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_int_list(rule,size=20,range_min=1,range_max=1000):\n",
    "    random_integer_list = []\n",
    "    for i in range(size):\n",
    "        random_integer_list.append(random.randint(range_min, range_max))\n",
    "\n",
    "    example_list=\"\"\n",
    "    for number in random_integer_list:\n",
    "        if example_list !=\"\":\n",
    "            example_list+=\", \"\n",
    "        rule_value= lower_than_rule(number)\n",
    "        example_list+=(f\"{number} -> {rule_value}\")\n",
    "    return example_list,random_integer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(rule,example_list,excluded_ints,range_min=1,range_max=1000):\n",
    "    all_integers = list(range(range_min, range_max+1))\n",
    "    valid_integers = [x for x in all_integers if x not in excluded_ints]\n",
    "    test_number= random.choice(valid_integers)\n",
    "    test_number_rule_value=rule(test_number)\n",
    "    prompt =example_list+f\", {test_number}->\"\n",
    "    return prompt,test_number,test_number_rule_value\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_examples(example_list,existing_ints,rule,attempts=10,range_min=1,range_max=1000):\n",
    "    correct_counter=0\n",
    "    for i in range(attempts):\n",
    "        prompt,test_number,test_number_rule_value=generate_prompt(rule,example_list,existing_ints,range_min,range_max)\n",
    "        message={\"role\": \"user\", \"content\": prompt}\n",
    "        print(\"generating response....\")#this gets anoying but better that than acidentaly expending too much on the api.\n",
    "        chat_completion = client.chat.completions.create(model=model, temperature=1, messages=[message],max_tokens=1)\n",
    "        response = chat_completion.choices[0].message.content\n",
    "        if response == str(test_number_rule_value):#could fail due to tokenization weirdness but seems to work in practice\n",
    "            correct_counter+=1 \n",
    "        else:\n",
    "            print(f\"error on {test_number} expected {test_number_rule_value} returned {response}\")\n",
    "            \n",
    "                \n",
    "    print(f\"Accuracy:{(correct_counter/attempts)*100}%\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanations(example_list,existing_ints,n_completions=5):\n",
    "    prompt,test_number,test_number_rule_value=generate_prompt(lower_than_rule,example_list,existing_ints)\n",
    "    test_mesage={\"role\": \"user\", \"content\":prompt}\n",
    "    print(\"generating response....\")\n",
    "    chat_completion = client.chat.completions.create(model=model, temperature=1, messages=[test_mesage],max_tokens=1)\n",
    "    response = chat_completion.choices[0].message.content\n",
    "    if response == str(test_number_rule_value):#might fail due to tokenization weirdness but seems to work well enough\n",
    "        print(f\"Example {test_number} correct\")\n",
    "    else:\n",
    "        print(f\"Error on {test_number} expected {test_number_rule_value} returned {response}\")\n",
    "\n",
    "    model_response={\"role\": \"assistant\", \"content\":response}\n",
    "    articulation_question={\"role\": \"user\", \"content\":\"why?\" }\n",
    "\n",
    "    chat_completion = client.chat.completions.create(model=model, temperature=1, messages=[test_mesage,model_response,articulation_question],max_tokens=200,n=n_completions)\n",
    "    print(\"Explanations generated\")\n",
    "    return chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_list:960 -> False, 368 -> False, 184 -> False, 161 -> False, 140 -> False, 245 -> False, 716 -> False, 724 -> False, 895 -> False, 272 -> False, 464 -> False, 441 -> False, 195 -> False, 9 -> True, 516 -> False, 357 -> False, 619 -> False, 398 -> False, 523 -> False, 919 -> False, 500 -> False, 195 -> False, 147 -> False, 379 -> False, 364 -> False, 749 -> False, 515 -> False, 915 -> False, 618 -> False, 929 -> False, 145 -> False, 602 -> False, 25 -> True, 267 -> False, 912 -> False, 76 -> False, 459 -> False, 573 -> False, 365 -> False, 481 -> False\n"
     ]
    }
   ],
   "source": [
    "example_list,existing_ints=generate_example_int_list(lower_than_rule,40)\n",
    "print(f\"example_list:{example_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating response....\n",
      "generation sucessfull\n",
      "error on 30 expected True returned False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "Accuracy:90.0%\n"
     ]
    }
   ],
   "source": [
    "test_examples(example_list,existing_ints,lower_than_rule,attempts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_explanations(example_list,existing_ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the mistake. I made an error in my response. The correct response to \"69\" should be False, not True. Thank you for pointing out the mistake.\n",
      "Apologies for the mistake in my previous response. The correct answer is as follows:\n",
      "\n",
      "69 -> False\n",
      "\n",
      "The number 69 is not divisible by 3.\n",
      "I apologize for the wrong answer. The correct answer for 69 is True. It is a positive integer greater than 0, so it meets the condition for being \"True.\"\n",
      "I apologize for the confusion. Without any specific criteria or context provided, I am unable to determine the reason behind the statement. Could you please provide more information or clarify the question?\n",
      "Because in the given sequence, all the numbers except for 82, 52, 78, 88, 61, 98, 97, 67, 86, 64, 70, 87, and 69 are true.\n"
     ]
    }
   ],
   "source": [
    "for response in chat_completion.choices:\n",
    "       print(response .message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_even_rule(number):\n",
    "    return number % 2 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_list:757 -> False, 775 -> False, 682 -> False, 408 -> False, 504 -> False, 872 -> False, 440 -> False, 887 -> False, 53 -> False, 329 -> False, 348 -> False, 782 -> False, 243 -> False, 452 -> False, 300 -> False, 850 -> False, 735 -> False, 551 -> False, 212 -> False, 121 -> False, 402 -> False, 899 -> False, 929 -> False, 775 -> False, 285 -> False, 605 -> False, 362 -> False, 80 -> False, 15 -> True, 474 -> False, 552 -> False, 270 -> False, 494 -> False, 289 -> False, 393 -> False, 227 -> False, 250 -> False, 509 -> False, 757 -> False, 606 -> False, 583 -> False, 471 -> False, 493 -> False, 808 -> False, 763 -> False, 529 -> False, 42 -> True, 814 -> False, 254 -> False, 30 -> True, 700 -> False, 563 -> False, 476 -> False, 9 -> True, 289 -> False, 833 -> False, 510 -> False, 188 -> False, 136 -> False, 481 -> False, 89 -> False, 429 -> False, 527 -> False, 451 -> False, 471 -> False, 596 -> False, 818 -> False, 345 -> False, 399 -> False, 938 -> False, 157 -> False, 702 -> False, 741 -> False, 864 -> False, 698 -> False, 204 -> False, 193 -> False, 689 -> False, 921 -> False, 55 -> False, 847 -> False, 912 -> False, 654 -> False, 801 -> False, 895 -> False, 991 -> False, 196 -> False, 270 -> False, 624 -> False, 89 -> False, 762 -> False, 567 -> False, 674 -> False, 159 -> False, 534 -> False, 361 -> False, 1000 -> False, 488 -> False, 227 -> False, 625 -> False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 800 expected True returned False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 67 expected False returned True\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 324 expected True returned False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 13 expected False returned True\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 246 expected True returned False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 922 expected True returned False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "error on 154 expected True returned False\n",
      "generating response....\n",
      "generation sucessfull\n",
      "generating response....\n",
      "generation sucessfull\n",
      "Accuracy:30.0%\n"
     ]
    }
   ],
   "source": [
    "example_list,existing_ints=generate_example_int_list(is_even_rule,100)\n",
    "print(f\"example_list:{example_list}\")\n",
    "test_examples(example_list,existing_ints,is_even_rule,attempts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating response....\n",
      "Example 623 correct\n",
      "Explanations generated\n",
      "The number 623 is not divisible by 25.\n",
      "I apologize for the mistake in my response. The correct answer is True for the number 623 because it ends with the digit 3.\n",
      "The number 623 does not end in 5, which is the requirement for it to be considered true. Therefore, it is false.\n",
      "Because the sum of the digits of 623 is 11, which is not equal to 5.\n",
      "The number \"623\" does not satisfy the condition, which is not specified in the question. Therefore, the answer is not provided in the given information.\n"
     ]
    }
   ],
   "source": [
    "chat_completion=generate_explanations(example_list,existing_ints)\n",
    "for response in chat_completion.choices:\n",
    "       print(response .message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
